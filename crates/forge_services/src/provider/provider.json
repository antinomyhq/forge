[
  {
    "id": "forge",
    "api_key_vars": "FORGE_API_KEY",
    "url_param_vars": [],
    "response_type": "OpenAI",
    "url": "https://antinomy.ai/api/v1/chat/completions",
    "models": "https://antinomy.ai/api/v1/models"
  },
  {
    "id": "open_router",
    "api_key_vars": "OPENROUTER_API_KEY",
    "url_param_vars": [],
    "response_type": "OpenAI",
    "url": "https://openrouter.ai/api/v1/chat/completions",
    "models": "https://openrouter.ai/api/v1/models"
  },
  {
    "id": "requesty",
    "api_key_vars": "REQUESTY_API_KEY",
    "url_param_vars": [],
    "response_type": "OpenAI",
    "url": "https://router.requesty.ai/v1/chat/completions",
    "models": "https://router.requesty.ai/v1/models"
  },
  {
    "id": "xai",
    "api_key_vars": "XAI_API_KEY",
    "url_param_vars": [],
    "response_type": "OpenAI",
    "url": "https://api.x.ai/v1/chat/completions",
    "models": "https://api.x.ai/v1/models"
  },
  {
    "id": "openai",
    "api_key_vars": "OPENAI_API_KEY",
    "url_param_vars": ["OPENAI_URL"],
    "response_type": "OpenAI",
    "url": "{{#if OPENAI_URL}}{{OPENAI_URL}}{{else}}https://api.openai.com/v1{{/if}}/chat/completions",
    "models": "{{#if OPENAI_URL}}{{OPENAI_URL}}{{else}}https://api.openai.com/v1{{/if}}/models"
  },
  {
    "id": "anthropic",
    "api_key_vars": "ANTHROPIC_API_KEY",
    "url_param_vars": ["ANTHROPIC_URL"],
    "response_type": "Anthropic",
    "url": "{{ANTHROPIC_URL}}/messages",
    "models": "{{ANTHROPIC_URL}}/models"
  },
  {
    "id": "cerebras",
    "api_key_vars": "CEREBRAS_API_KEY",
    "url_param_vars": [],
    "response_type": "OpenAI",
    "url": "https://api.cerebras.ai/v1/chat/completions",
    "models": "https://api.cerebras.ai/v1/models"
  },
  {
    "id": "zai",
    "api_key_vars": "ZAI_API_KEY",
    "url_param_vars": [],
    "response_type": "OpenAI",
    "url": "https://api.z.ai/api/paas/v4/chat/completions",
    "models": [
      {
        "id": "glm-4.6",
        "name": "GLM-4.6",
        "description": "Latest flagship model series, foundational models specifically designed for agent applications with 200K context window and 128K maximum output",
        "context_length": 200000,
        "tools_supported": true,
        "supports_parallel_tool_calls": true,
        "supports_reasoning": true
      },
      {
        "id": "glm-4.5",
        "name": "GLM-4.5",
        "description": "Advanced model with 128K context window and 96K maximum output, supports chain of thought",
        "context_length": 128000,
        "tools_supported": true,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": true
      },
      {
        "id": "glm-4.5-air",
        "name": "GLM-4.5-air",
        "description": "Lightweight version of GLM-4.5 with 128K context window and optimized performance",
        "context_length": 128000,
        "tools_supported": true,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": true
      },
      {
        "id": "glm-4.5-x",
        "name": "GLM-4.5-x",
        "description": "Extended version of GLM-4.5 with 128K context window and enhanced capabilities",
        "context_length": 128000,
        "tools_supported": true,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": true
      },
      {
        "id": "glm-4.5-airx",
        "name": "GLM-4.5-airx",
        "description": "Optimized version of GLM-4.5 with 128K context window and balanced performance and capabilities",
        "context_length": 128000,
        "tools_supported": true,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": true
      },
      {
        "id": "glm-4.5-flash",
        "name": "GLM-4.5-flash",
        "description": "Fast inference model with 128K context window for quick responses",
        "context_length": 128000,
        "tools_supported": true,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": true
      },
      {
        "id": "glm-4-32b-0414-128k",
        "name": "GLM-4-32B-0414-128K",
        "description": "32B parameter model with 128K context window and 16K maximum output",
        "context_length": 128000,
        "tools_supported": true,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": false
      }
    ]
  },
  {
    "id": "zai_coding",
    "api_key_vars": "ZAI_CODING_API_KEY",
    "url_param_vars": [],
    "response_type": "OpenAI",
    "url": "https://api.z.ai/api/coding/paas/v4/chat/completions",
    "models": [
      {
        "id": "glm-4.6",
        "name": "GLM-4.6",
        "description": "Latest flagship model series, foundational models specifically designed for agent applications with 200K context window and 128K maximum output",
        "context_length": 200000,
        "tools_supported": true,
        "supports_parallel_tool_calls": true,
        "supports_reasoning": true
      },
      {
        "id": "glm-4.5",
        "name": "GLM-4.5",
        "description": "Advanced model with 128K context window and 96K maximum output, supports chain of thought",
        "context_length": 128000,
        "tools_supported": true,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": true
      },
      {
        "id": "glm-4.5-air",
        "name": "GLM-4.5-air",
        "description": "Lightweight version of GLM-4.5 with 128K context window and optimized performance",
        "context_length": 128000,
        "tools_supported": true,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": true
      },
      {
        "id": "glm-4.5-x",
        "name": "GLM-4.5-x",
        "description": "Extended version of GLM-4.5 with 128K context window and enhanced capabilities",
        "context_length": 128000,
        "tools_supported": true,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": true
      },
      {
        "id": "glm-4.5-airx",
        "name": "GLM-4.5-airx",
        "description": "Optimized version of GLM-4.5 with 128K context window and balanced performance and capabilities",
        "context_length": 128000,
        "tools_supported": true,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": true
      },
      {
        "id": "glm-4.5-flash",
        "name": "GLM-4.5-flash",
        "description": "Fast inference model with 128K context window for quick responses",
        "context_length": 128000,
        "tools_supported": true,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": true
      },
      {
        "id": "glm-4-32b-0414-128k",
        "name": "GLM-4-32B-0414-128K",
        "description": "32B parameter model with 128K context window and 16K maximum output",
        "context_length": 128000,
        "tools_supported": true,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": false
      }
    ]
  },
  {
    "id": "big_model",
    "api_key_vars": "BIG_MODEL_API_KEY",
    "url_param_vars": [],
    "response_type": "OpenAI",
    "url": "https://open.bigmodel.cn/api/paas/v4/chat/completions",
    "models": "https://open.bigmodel.cn/api/paas/v4/models"
  },
  {
    "id": "vertex_ai",
    "api_key_vars": "VERTEX_AI_AUTH_TOKEN",
    "url_param_vars": ["PROJECT_ID", "LOCATION"],
    "response_type": "OpenAI",
    "url": "{{#if (eq LOCATION \"global\")}}https://aiplatform.googleapis.com/v1/projects/{{PROJECT_ID}}/locations/{{LOCATION}}/endpoints/openapi/chat/completions{{else}}https://{{LOCATION}}-aiplatform.googleapis.com/v1/projects/{{PROJECT_ID}}/locations/{{LOCATION}}/endpoints/openapi/chat/completions{{/if}}",
    "models": "{{#if (eq LOCATION \"global\")}}https://aiplatform.googleapis.com/v1/projects/{{PROJECT_ID}}/locations/{{LOCATION}}/endpoints/openapi/models{{else}}https://{{LOCATION}}-aiplatform.googleapis.com/v1/projects/{{PROJECT_ID}}/locations/{{LOCATION}}/endpoints/openapi/models{{/if}}"
  },
  {
    "id": "azure",
    "api_key_vars": "AZURE_API_KEY",
    "url_param_vars": [
      "AZURE_RESOURCE_NAME",
      "AZURE_DEPLOYMENT_NAME",
      "AZURE_API_VERSION"
    ],
    "response_type": "OpenAI",
    "url": "https://{{AZURE_RESOURCE_NAME}}.openai.azure.com/openai/deployments/{{AZURE_DEPLOYMENT_NAME}}/chat/completions?api-version={{AZURE_API_VERSION}}",
    "models": "https://{{AZURE_RESOURCE_NAME}}.openai.azure.com/openai/models?api-version={{AZURE_API_VERSION}}"
  }
]
