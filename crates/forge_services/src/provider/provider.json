[
  {
    "id": "forge",
    "api_key_vars": "FORGE_API_KEY",
    "url_param_vars": [],
    "response_type": "openai",
    "url": "https://antinomy.ai/api/v1/chat/completions",
    "models": "https://antinomy.ai/api/v1/models",
    "auth_methods": [
      "api_key"
    ]
  },
  {
    "id": "github_copilot",
    "api_key_vars": "GITHUB_COPILOT_API_KEY",
    "url_param_vars": [],
    "response_type": "openai",
    "url": "https://api.githubcopilot.com/chat/completions",
    "models": "https://api.githubcopilot.com/models",
    "auth_methods": [
      {
        "oauth_device": {
          "auth_url": "https://github.com/login/device/code",
          "token_url": "https://github.com/login/oauth/access_token",
          "client_id": "Iv1.b507a08c87ecfe98",
          "scopes": ["read:user"],
          "use_pkce": false,
          "token_refresh_url": "https://api.github.com/copilot_internal/v2/token",
          "custom_headers": {
            "User-Agent": "GitHubCopilotChat/0.26.7",
            "Accept": "application/json",
            "editor-version": "vscode/1.99.3",
            "editor-plugin-version": "copilot-chat/0.26.7"
          }
        }
      }
    ]
  },
  {
    "id": "open_router",
    "api_key_vars": "OPENROUTER_API_KEY",
    "url_param_vars": [],
    "response_type": "openai",
    "url": "https://openrouter.ai/api/v1/chat/completions",
    "models": "https://openrouter.ai/api/v1/models",
    "auth_methods": [
      "api_key"
    ]
  },
  {
    "id": "requesty",
    "api_key_vars": "REQUESTY_API_KEY",
    "url_param_vars": [],
    "response_type": "openai",
    "url": "https://router.requesty.ai/v1/chat/completions",
    "models": "https://router.requesty.ai/v1/models",
    "auth_methods": [
      "api_key"
    ]
  },
  {
    "id": "xai",
    "api_key_vars": "XAI_API_KEY",
    "url_param_vars": [],
    "response_type": "openai",
    "url": "https://api.x.ai/v1/chat/completions",
    "models": "https://api.x.ai/v1/models",
    "auth_methods": [
      "api_key"
    ]
  },
  {
    "id": "openai",
    "api_key_vars": "OPENAI_API_KEY",
    "url_param_vars": [],
    "response_type": "openai",
    "url": "https://api.openai.com/v1/chat/completions",
    "models": "https://api.openai.com/v1/models",
    "auth_methods": [
      "api_key"
    ]
  },
  {
    "id": "openai_compatible",
    "api_key_vars": "OPENAI_API_KEY",
    "url_param_vars": ["BASE_URL"],
    "response_type": "openai",
    "url": "{{BASE_URL}}/chat/completions",
    "models": "{{BASE_URL}}/models",
    "auth_methods": [
      "api_key"
    ]
  },
  {
    "id": "anthropic",
    "api_key_vars": "ANTHROPIC_API_KEY",
    "url_param_vars": [],
    "response_type": "anthropic",
    "url": "https://api.anthropic.com/v1/messages",
    "models": "https://api.anthropic.com/v1/models",
    "auth_methods": [
      "api_key",
      {
        "oauth_code": {
          "auth_url": "https://claude.ai/oauth/authorize",
          "token_url": "https://console.anthropic.com/v1/oauth/token",
          "client_id": "9d1c250a-e61b-44d9-88ed-5944d1962f5e",
          "scopes": ["org:create_api_key", "user:profile", "user:inference"],
          "redirect_uri": "https://console.anthropic.com/oauth/code/callback",
          "use_pkce": true,
          "extra_auth_params": {
            "code": "true"
          }
        }
      }
    ]
  },
  {
    "id": "anthropic_compatible",
    "api_key_vars": "ANTHROPIC_API_KEY",
    "url_param_vars": ["ANTHROPIC_URL"],
    "response_type": "anthropic",
    "url": "{{ANTHROPIC_URL}}/messages",
    "models": "{{ANTHROPIC_URL}}/models",
    "auth_methods": [
      "api_key"
    ]
  },
  {
    "id": "cerebras",
    "api_key_vars": "CEREBRAS_API_KEY",
    "url_param_vars": [],
    "response_type": "openai",
    "url": "https://api.cerebras.ai/v1/chat/completions",
    "models": "https://api.cerebras.ai/v1/models",
    "auth_methods": [
      "api_key"
    ]
  },
  {
    "id": "zai",
    "api_key_vars": "ZAI_API_KEY",
    "url_param_vars": [],
    "response_type": "openai",
    "url": "https://api.z.ai/api/paas/v4/chat/completions",
    "models": [
      {
        "id": "glm-4.6",
        "name": "GLM-4.6",
        "description": "Latest flagship model series, foundational models specifically designed for agent applications with 200K context window and 128K maximum output",
        "context_length": 200000,
        "tools_supported": true,
        "supports_parallel_tool_calls": true,
        "supports_reasoning": true
      },
      {
        "id": "glm-4.5",
        "name": "GLM-4.5",
        "description": "Advanced model with 128K context window and 96K maximum output, supports chain of thought",
        "context_length": 128000,
        "tools_supported": true,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": true
      },
      {
        "id": "glm-4.5-air",
        "name": "GLM-4.5-air",
        "description": "Lightweight version of GLM-4.5 with 128K context window and optimized performance",
        "context_length": 128000,
        "tools_supported": true,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": true
      },
      {
        "id": "glm-4.5-x",
        "name": "GLM-4.5-x",
        "description": "Extended version of GLM-4.5 with 128K context window and enhanced capabilities",
        "context_length": 128000,
        "tools_supported": true,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": true
      },
      {
        "id": "glm-4.5-airx",
        "name": "GLM-4.5-airx",
        "description": "Optimized version of GLM-4.5 with 128K context window and balanced performance and capabilities",
        "context_length": 128000,
        "tools_supported": true,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": true
      },
      {
        "id": "glm-4.5-flash",
        "name": "GLM-4.5-flash",
        "description": "Fast inference model with 128K context window for quick responses",
        "context_length": 128000,
        "tools_supported": true,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": true
      },
      {
        "id": "glm-4-32b-0414-128k",
        "name": "GLM-4-32B-0414-128K",
        "description": "32B parameter model with 128K context window and 16K maximum output",
        "context_length": 128000,
        "tools_supported": true,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": false
      }
    ],
    "auth_methods": [
      "api_key"
    ]

  },
  {
    "id": "zai_coding",
    "api_key_vars": "ZAI_CODING_API_KEY",
    "url_param_vars": [],
    "response_type": "openai",
    "url": "https://api.z.ai/api/coding/paas/v4/chat/completions",
    "models": [
      {
        "id": "glm-4.6",
        "name": "GLM-4.6",
        "description": "Latest flagship model series, foundational models specifically designed for agent applications with 200K context window and 128K maximum output",
        "context_length": 200000,
        "tools_supported": true,
        "supports_parallel_tool_calls": true,
        "supports_reasoning": true
      },
      {
        "id": "glm-4.5",
        "name": "GLM-4.5",
        "description": "Advanced model with 128K context window and 96K maximum output, supports chain of thought",
        "context_length": 128000,
        "tools_supported": true,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": true
      },
      {
        "id": "glm-4.5-air",
        "name": "GLM-4.5-air",
        "description": "Lightweight version of GLM-4.5 with 128K context window and optimized performance",
        "context_length": 128000,
        "tools_supported": true,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": true
      },
      {
        "id": "glm-4.5-x",
        "name": "GLM-4.5-x",
        "description": "Extended version of GLM-4.5 with 128K context window and enhanced capabilities",
        "context_length": 128000,
        "tools_supported": true,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": true
      },
      {
        "id": "glm-4.5-airx",
        "name": "GLM-4.5-airx",
        "description": "Optimized version of GLM-4.5 with 128K context window and balanced performance and capabilities",
        "context_length": 128000,
        "tools_supported": true,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": true
      },
      {
        "id": "glm-4.5-flash",
        "name": "GLM-4.5-flash",
        "description": "Fast inference model with 128K context window for quick responses",
        "context_length": 128000,
        "tools_supported": true,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": true
      },
      {
        "id": "glm-4-32b-0414-128k",
        "name": "GLM-4-32B-0414-128K",
        "description": "32B parameter model with 128K context window and 16K maximum output",
        "context_length": 128000,
        "tools_supported": true,
        "supports_parallel_tool_calls": false,
        "supports_reasoning": false
      }
    ],
    "auth_methods": [
      "api_key"
    ]
  },
  {
    "id": "big_model",
    "api_key_vars": "BIG_MODEL_API_KEY",
    "url_param_vars": [],
    "response_type": "openai",
    "url": "https://open.bigmodel.cn/api/paas/v4/chat/completions",
    "models": "https://open.bigmodel.cn/api/paas/v4/models",
    "auth_methods": [
      "api_key"
    ]
  },
  {
    "id": "vertex_ai",
    "api_key_vars": "VERTEX_AI_AUTH_TOKEN",
    "url_param_vars": ["PROJECT_ID", "LOCATION"],
    "response_type": "openai",
    "url": "{{#if (eq LOCATION \"global\")}}https://aiplatform.googleapis.com/v1/projects/{{PROJECT_ID}}/locations/{{LOCATION}}/endpoints/openapi/chat/completions{{else}}https://{{LOCATION}}-aiplatform.googleapis.com/v1/projects/{{PROJECT_ID}}/locations/{{LOCATION}}/endpoints/openapi/chat/completions{{/if}}",
    "models": "{{#if (eq LOCATION \"global\")}}https://aiplatform.googleapis.com/v1/projects/{{PROJECT_ID}}/locations/{{LOCATION}}/endpoints/openapi/models{{else}}https://{{LOCATION}}-aiplatform.googleapis.com/v1/projects/{{PROJECT_ID}}/locations/{{LOCATION}}/endpoints/openapi/models{{/if}}",
    "auth_methods": [
      "api_key"
    ]
  },
  {
    "id": "azure",
    "api_key_vars": "AZURE_API_KEY",
    "url_param_vars": [
      "AZURE_RESOURCE_NAME",
      "AZURE_DEPLOYMENT_NAME",
      "AZURE_API_VERSION"
    ],
    "response_type": "openai",
    "url": "https://{{AZURE_RESOURCE_NAME}}.openai.azure.com/openai/deployments/{{AZURE_DEPLOYMENT_NAME}}/chat/completions?api-version={{AZURE_API_VERSION}}",
    "models": "https://{{AZURE_RESOURCE_NAME}}.openai.azure.com/openai/models?api-version={{AZURE_API_VERSION}}",
    "auth_methods": [
      "api_key"
    ]
  }
]
